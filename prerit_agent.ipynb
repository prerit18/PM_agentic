{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed150c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important key from the env file.\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0780b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46692ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading linked in profile in the pdf format.\n",
    "reader = PdfReader(\"me/profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f13d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "prerit.mehrotra@gmail.com\n",
      "www.linkedin.com/in/prerit-\n",
      "mehrotra-b8792678 (LinkedIn)\n",
      "Top Skills\n",
      "Data Engineering\n",
      "Neo4j\n",
      "PySpark\n",
      "Certifications\n",
      "DS  C13 Course 2&3 LOA\n",
      "AWS Machine Learning Engineer\n",
      "Nanodegree\n",
      "Neo4j Certified Professional\n",
      "AWS Machine Learning Engineer\n",
      "Nanodegree\n",
      "DS C13 Diploma Certificate\n",
      "Prerit Mehrotra\n",
      "Data Engineer at Natwest\n",
      "United Kingdom\n",
      "Experience\n",
      "Royal Bank of Scotland\n",
      "Data Engineer\n",
      "March 2011 - Present (14 years 6 months)\n",
      "Mphasis\n",
      "Software Engineer\n",
      "January 2010 - September 2011 (1 year 9 months)\n",
      "Education\n",
      "B. M. S. College of Engineering\n",
      "International Institute of Information Technology Bangalore\n",
      "PGDDS, Data Science\n",
      "Udacity\n",
      "  Page 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding further contecxt\n",
    "with open(\"me/p_summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23888211",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Prerit Mehrotra\"\n",
    "# giving system prompt\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and testing basic chat agent function to start with\n",
    "def chat(message, history):\n",
    "    system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7e3c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using gradio to create a chat interface and calling the chat function\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "501a86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pydantic to create the class of the evaluation model for the agent\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b714001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system prompt for the evaluation model\n",
    "evaluation_system_prompt = \"\"\"\n",
    "You are an expert in evaluating the quality of responses from an agent.\n",
    "You are given a response and a question.\n",
    "You need to evaluate the response based on the question.\n",
    "You need to return a score between 0 and 100.\n",
    "The agent has been instructed to stay in character as Prerit Mehrotra.\n",
    "The agent has been given a summary of Prerit Mehrotra's background and LinkedIn profile which you can use to answer questions.\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website.\n",
    "If you don't know the answer, say so.\n",
    "\"\"\"\n",
    "evaluation_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluation_system_prompt += f\"With this context, please evaluate the response based on the question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25a6f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9924dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling gemini llm key for the evaluator agent\n",
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61c3fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluation_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9bfbd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the evaluation fuction by passing reply, before that asking the question from the chat agent\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you play any sport?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d700cb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'While my primary focus has been on my career in data engineering and exploring Agentic AI use cases, I do enjoy engaging in sports when I can find the time. Participating in sports can be a great way to maintain a balanced lifestyle and connect with others outside of work. What about you? Do you have a favorite sport?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the reply\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec2059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is acceptable as it gives an answer to the question while also maintaining the persona.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling evaluate function to test\n",
    "evaluate(reply, \"which sport do you play?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a5b463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function if we need to ask the agent to rerun if the evaluator agent failed the reply from the chat agent\n",
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0dd8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the chat agent funtion now with the evaluator agent and rerun funtion\n",
    "def chat(message, history):\n",
    "    #system = system_prompt\n",
    "    # forcing the evaluator fundction to fail by giving if condition, if the message contains sport the original reponse from chat agent will converted \n",
    "    # into pig latin that will fail the reply by the evaluator agent.\n",
    "    if \"sport\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25c2715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable. The agent is not in character and is replying in a bizarre manner. It should state that it does not have information about sports related activities.\n"
     ]
    }
   ],
   "source": [
    "# popping up a chat interface\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16c878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
